---
# tasks file for ollama

- name: Install dependencies for Ollama
  ansible.builtin.apt:
    name:
      - curl
      - systemd
    state: present
    update_cache: true
  tags:
    - ollama
    - packages
    - ai
    - llm
    - dependencies

- name: Check if Ollama is already installed
  ansible.builtin.command: ollama --version
  register: ollama_installed
  changed_when: false
  failed_when: false
  tags:
    - ollama
    - ai
    - llm

- name: Download Ollama installation script
  ansible.builtin.get_url:
    url: https://ollama.com/install.sh
    dest: /tmp/ollama_install.sh
    mode: '0755'
  when: ollama_installed.rc != 0
  tags:
    - ollama
    - packages
    - ai
    - llm

- name: Install Ollama
  ansible.builtin.shell: |
    set -o pipefail
    /tmp/ollama_install.sh
  args:
    executable: /bin/bash
    creates: /usr/local/bin/ollama
  when: ollama_installed.rc != 0
  tags:
    - ollama
    - packages
    - ai
    - llm

- name: Clean up installation script
  ansible.builtin.file:
    path: /tmp/ollama_install.sh
    state: absent
  when: ollama_installed.rc != 0
  tags:
    - ollama
    - packages
    - ai
    - llm
    - cleanup

- name: Create Ollama systemd override directory
  ansible.builtin.file:
    path: /etc/systemd/system/ollama.service.d
    state: directory
    mode: '0755'
    owner: root
    group: root
  tags:
    - ollama
    - ai
    - llm
    - service
    - configuration

- name: Configure Ollama to listen on all interfaces
  ansible.builtin.copy:
    dest: /etc/systemd/system/ollama.service.d/override.conf
    mode: '0644'
    owner: root
    group: root
    content: |
      [Service]
      Environment="OLLAMA_HOST={{ ollama_host }}"
  notify: Restart ollama service
  tags:
    - ollama
    - ai
    - llm
    - service
    - configuration

- name: Reload systemd daemon
  ansible.builtin.systemd:
    daemon_reload: true
  tags:
    - ollama
    - ai
    - llm
    - service

- name: Ensure Ollama service is enabled and started
  ansible.builtin.systemd:
    name: ollama
    state: "{{ ollama_service_state }}"
    enabled: "{{ ollama_service_enabled }}"
  tags:
    - ollama
    - ai
    - llm
    - service

- name: Wait for Ollama service to be ready
  ansible.builtin.wait_for:
    host: localhost
    port: 11434
    delay: 2
    timeout: 30
  tags:
    - ollama
    - ai
    - llm
    - service

- name: Check if models are already pulled
  ansible.builtin.command: ollama list
  register: ollama_list
  changed_when: false
  failed_when: false
  tags:
    - ollama
    - ai
    - llm
    - models

- name: Pull Ollama models
  ansible.builtin.command: "ollama pull {{ item }}"
  loop: "{{ ollama_models }}"
  when: item not in ollama_list.stdout
  register: ollama_pull_result
  changed_when: "'success' in ollama_pull_result.stdout or ollama_pull_result.rc == 0"
  tags:
    - ollama
    - ai
    - llm
    - models

- name: Verify Ollama installation
  ansible.builtin.command: ollama --version
  register: ollama_version_output
  changed_when: false
  tags:
    - ollama
    - ai
    - llm

- name: List installed Ollama models
  ansible.builtin.command: ollama list
  register: ollama_models_list
  changed_when: false
  tags:
    - ollama
    - ai
    - llm
    - models

- name: Pull Open WebUI Docker image
  community.docker.docker_image:
    name: "{{ open_webui_image }}"
    source: pull
    state: present
  when: open_webui_enabled
  tags:
    - ollama
    - ai
    - llm
    - docker
    - open-webui

- name: Manage Open WebUI Docker container
  community.docker.docker_container:
    name: "{{ open_webui_container_name }}"
    image: "{{ open_webui_image }}"
    state: started
    restart_policy: unless-stopped
    ports:
      - "{{ open_webui_port }}:{{ open_webui_internal_port }}"
    env:
      OLLAMA_API_BASE_URL: "{{ ollama_api_base_url }}"
    etc_hosts:
      host.docker.internal: host-gateway
    comparisons:
      image: strict
      env: strict
      ports: strict
  when: open_webui_enabled
  tags:
    - ollama
    - ai
    - llm
    - docker
    - open-webui

- name: Wait for Open WebUI to be ready
  ansible.builtin.wait_for:
    host: localhost
    port: "{{ open_webui_port }}"
    delay: 5
    timeout: 60
  when: open_webui_enabled
  tags:
    - ollama
    - ai
    - llm
    - docker
    - open-webui
